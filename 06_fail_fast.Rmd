# Code that Fails

Your code will fail. Not once, not twice, but hundreds, thousands of times in the course of a large data science project. Everybody's code fails, many times. Your code, my code, Hadley Wickham's code. Not because we are bad at what we do, but because it is not possible to foresee all the possible ways the code will be used or all the possible data inputs that the code will run against at the moment we write it. Getting better at programming does not mean you will write fault-free code (although you will make fewer errors as you grow more experienced), but writing code that fails fast and informatively. 
Writing such code means that you will spent more time developing than with the *random walk* method described in the previous chapter. This is an investment that will pay off big time as your project grows in complexity. 

But before we look into how to write code that fails fast and informative, why is this important for Agile Data Science? High quality code is part of the twelve principles, but this is a means to an end. The essence of Agile is continuous delivery. Updating and shipping your product everytime you made progress can only be done when your code is adjustable. As the project advances, the end-to-end product will grow in complexity. Sooner rather than later it will reach a point in which you cannot have a full overview of all the aspects of the product anymore. When introducing a new feature you want to make sure all the other elements in the code base keep doing what they were designed for. If not, you want to be instructed clearly what is going wrong so you can either adjust the newly introduced feature or modify the existing elements so it works with the new feature. If everytime you want to make a change the whole thing comes tumbling done without informing you what goes wrong, you cannot achieve the objective of fast, continuous delivery.

## Assumptions to your Data

Automation means not calling the functions yourself anymore. You just flip the switch and the whole thing is set in motion. This means that you are no longer get the inmediate feedback you are used to when calling the functions yourself. When something goes wrong the whole thing just breaks with an error message. When you are lucky the error message is informative and you are quick to find the bug. When you are not, you may be confronted with `object of type 'closure' is not subsettable`, you may have grumpy afternoon ahead. Best to not depend on luck, but make sure you will always get a proper indication what went wrong. 

### Type Checking

Most languages using functional programming are strongly typed. This means that for every argument that a function takes, its datatype is specified at function creation, as well as the datatype that the output takes. When the function is than called it is first checked if the data on which it is called is of the correct type, or at least can be forced to the specified type. If not, it will break inmediately and will tell the user why. R is weakly typed, the data type of the function arguments are not specified. When a function is called it just has a go on the objects that are fed to it. The function only breaks when somewhere in the body another function gets called with an invalid data type. Take the following for instance:

```{r}
add_two_numbers <- function(x, y) {
  print("Reaching this")
  print("and this")
  print("Doing some random other stuff")
  x + y
}
```

Now, what will happen if we accidently call it on a string? It will only break when we hit the `+` operator, all the code before it runs. The error message it gives us, is not so informative that we inmediately figure out what goes wrong.

```{r, error = TRUE}
add_two_numbers(42, "MacGyver")
```

Pfff, what is a binary operator again? When this functions is part of a framework in which higher order functions call lower order functions you may be up for an hour or two of sifting through your code to locate the bug. Fortunately type checking is very easily add to a function by asserting all argument data types in `stopifnot`. 

```{r, error = TRUE}
add_two_numbers <- function(x, y) {
  stopifnot(is.numeric(x), is.numeric(y))
  print("Reaching this")
  print("and this")
  print("Doing some random other stuff")
  x + y
}

add_two_numbers(42, "MacGyver")
```
We are now specifically informed, which argument does not meet the assumptions and in what the name of the subfunction is. 

### Column Validation

Central to most data products will be the modification of data frames. Probably most functions you'll create are very specific to your project and will be called only once. For these cases you want to save yourself the overhead of making each function completely generic by parametrising the column names that are used. Say you want to add the log of the target to the data frame and you create the following function.
```{r}
add_log_target <- function(x) {
  stopifnot(is.data.frame(x))
  x$target_log <- log(x$target))
  x
}
```
Now what if `target` was mistakingly removed from `x` in the step preceding this one in the product. Will it throw an informativer error?

```{r, error = TRUE}
add_log_target(mtcars)
```
Uhh, no not exactly. Another of those R error beauties that will leave you clueless for a time. It is a good idea to check if all the columns that are required for the operations in the function are present before starting them. I use this little function,

```{r, error = TRUE}
df_has_cols <- function(x, cols, func) { 
  stopifnot(is.data.frame(x))
  if(!all(cols %in% colnames(x))) {
    not_present <- setdiff(cols, colnames(x))
    stop(paste(not_present, collapse = ", "), " missing from the data frame in function ", func[[1]])
 } 
```
which is added to each function that uses a data frame

```{r}
add_log_target <- function(x) {
  df_has_cols(x, "target", match.call())
  x$target_log <- log(x$target))
  x
}
add_log_target(mtcars)
```
(`match.call()` has to be added so it will return the name of the function that breaks for easy debugging).

### Data Validation

## Unit Testing

* slow down - think through scenarios
* externalise your memory
