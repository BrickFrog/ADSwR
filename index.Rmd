--- 
title: "Agile Machine Learning with R"
subtitle: "A workflow"
author: "Edwin Thoen"
output:
  html_document:
    df_print: paged
description: A workflow for doing machine learning in the R language, using Agile principles.
documentclass: book
link-citations: yes
bibliography:
- book.bib
- packages.bib
site: bookdown::bookdown_site
biblio-style: apalike
---

# About this text

Not even too long ago, when I was starting my career as a data scientist, I did not really have a workflow. Freshly graduated from an applied statistics master I entered the arena of Dutch business, employed by a small consulting firm. Neither the company I was with, nor the clients I was working for, nor myself had an understanding of what it meant to implement a statistical model or a machine learning method in the real world. Everybody was of course interested in this "Big Data" thing, so it did not take long before we I could start at clients, often without a clear idea what I was going to do. When we finally came to something that looked like a project, I plunged into it. Eager to deliver results quickly I loaded data extracts into R and started to applied all kinds of different models and algorithms on it. Findings ended up in the code comments of the R scripts, scripts that often grew to hundreds or even thousands of lines. To still have somekind of an overview I numbered the scripts serially, but this was about all the system I had. Soon I found myself amidst dozens of scripts and data exports of intermediate results that were no longer reproducible. The R session I was running *ad infinitum* was sometimes mistakenly closed, or it crashed (which was bound to happen as the memory used grew). I spent hours or even days to recreate the results when this happened. Deadlines were a nightmare, everything I had done so far had to be loaded, joined and compared at the last moment. More often than not, the model results appeared to be different from the indications in the notes I took earlier, with no idea if I was mistaken earlier, I was using the wrong data now, or some other source of error I was not aware of was introduced. Looking back at these times, I had no clue about the importance of a good workflow for doing larger data science projects. I was saved several times when plugs were pulled from the projects due to other reasons. If I was expected to bring the results to production then, it would certainly been a painful demasqu√©.

I learned a great deal since these day, both from other people's insights and from experience. Writing an R package that was shipped to CRAN enforced me to understand the basics of software engineering. Not being able to reproduce crucial results forced me to start thinking about end-to-end research and model building, controlling all the steps along the way. Recently, for the first time, I joined a Scrum team (frontend, backend, ux designer, product owner, second data scientis) to create a machine learning model that we brought to production using the agile principles. It was an inspiring experience from which I learned a great deal. My colleagues patiently explained the principles of Agile software development and together we discovered what did and did not work for machine learning.

## Writing out Loud

All these experiences culminated in the workflow that we are adhering to at work now and that I think is worthwhile sharing. It is heavily based on the principles of Agile software production, hence the title. We have explored which of the concepts from Agile did and did not work for data science and we got hands-on experience in working from these principles in an R project that actually got to production. Besides discussing the Agile theory in a data science context, I will how to use the R package structure to put it it into practise.

Workflows are subjective by nature, what I think is elegant and should be a best practise might not be appealing to you. That is okay. The objective of this writing is not to tell you how you should do your job. In fact, I am very interested in what you have to say about the topics I am writing about. Data science workflows are often grown out of individual trial-and-error rather than coming from a theoretical framework like Agile. If you have developed a habit that you think is worthwhile sharing, please do so by filing an [issue](https://github.com/EdwinTh/AMLwR). I might find your idea superior to my approach and I'll change the the text. Or I might think it is an equally valid way of tackeling a problem and I'll add it as an appendix to the chapter. This text is meant to be a living thing with the objective of documenting a workflow that yields optimal reproducibility, highly reproducible results and quality code. The more people share their best practises, the closer we get to this objective. Please follow along on this journey and get involved![^1] 

I will write and publish the chapters one by one. The intention is that the publication of each chapter will result in a discussion and revisions of that part Gradually, with your inputs, we might reach a text that can be a valuable research for many people doing machine learning and data science in general.

## Intended Audience

The title of this text has four components: *Agile*, *machine learning*, *R*, and *workflow*. When you are interested in all four, you are obviously at the right place. This text is not for you if you hope to learn about different algorithms and statistical techniques to do machine learning, more knowledgeable people have written many books on those topics. The workflow I present is completely separate from the algorithms you choose, as it focuses on code organisation and delivery. When you use python rather than R, you will still find this text valuable. Many workflow aspects will be applicable to your environment as well, you only will not benefit from the parts on using the R package structure and the use of R specific packages. Finally, this text is intended for everybody building a data science product in R. Whether a Shiny app or a complex statistical model, this text should be valuable for you as well. The iterative nature of Agile will make your process more effective and your stakeholders more involved. I contemplated calling it *Agile Data Science...* instead of *Agile Machine Learning...* to broaden the scope of the text, but frankly I have only done simple, internal use Shiny dashboards and quick statistical models. Therefore, I will stick to what I know well and only give examples of machine learning. I hope you will have little trouble translating the concepts to you own situation if it is other than machine learning. You are most welcome to do suggestions if you think the text will benefit from expanding to other examples as well.

[^1]: Also typo fixes and suggestions to improve the style of the text are highly appreciated by this nonnative in English.